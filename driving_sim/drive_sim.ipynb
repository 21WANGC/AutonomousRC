{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        \n",
    "        # Conv\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        # Feed into GRU.\n",
    "        self.gru = nn.GRU(self.feature_size, self.feature_size, batch_first=True)\n",
    "        self.decoder = nn.Linear(self.feature_size, self.vocab_size)\n",
    "        \n",
    "        # WEIGHT SHARING??\n",
    "        self.decoder.weight = self.fc3.weight\n",
    "        self.decoder.bias.data.zero_()\n",
    "        \n",
    "        self.best_accuracy = -1\n",
    "    \n",
    "    def forward(self, x, hidden_state=None):\n",
    "        batch_size = x.shape[0]\n",
    "        sequence_length = x.shape[1]\n",
    "        \n",
    "        # Conv\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # Feed into GRU.\n",
    "        x, hidden_state = self.gru(x, hidden_state)\n",
    "        x = self.decoder(x)\n",
    "        return x, hidden_state\n",
    "\n",
    "    # This defines the function that gives a probability distribution and implements the temperature computation.\n",
    "    def inference(self, x, hidden_state=None, temperature=1):\n",
    "        x = x.view(-1, 1)\n",
    "        x, hidden_state = self.forward(x, hidden_state)\n",
    "        x = x.view(1, -1)\n",
    "        x = x / max(temperature, 1e-20)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x, hidden_state\n",
    "\n",
    "    # Predefined loss function\n",
    "    def loss(self, prediction, label, reduction='mean'):\n",
    "        loss_val = F.cross_entropy(prediction.view(-1, self.vocab_size), label.view(-1), reduction=reduction)\n",
    "        return loss_val\n",
    "\n",
    "    # Saves the current model\n",
    "    def save_model(self, file_path, num_to_keep=1):\n",
    "        pt_util.save(self, file_path, num_to_keep)\n",
    "\n",
    "    # Saves the best model so far\n",
    "    def save_best_model(self, accuracy, file_path, num_to_keep=1):\n",
    "        if accuracy > self.best_accuracy:\n",
    "            self.save_model(file_path, num_to_keep)\n",
    "            self.best_accuracy = accuracy\n",
    "\n",
    "    def load_model(self, file_path):\n",
    "        pt_util.restore(self, file_path)\n",
    "\n",
    "    def load_last_model(self, dir_path):\n",
    "        return pt_util.restore_latest(self, dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pt_util\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = '/home/wangc21/datasets/ARC/right_loop/'\n",
    "DATA_PATH = '/home/wangc21/datasets/ARC/left_loop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_path, val=False, transform=None):\n",
    "        self.data_path = data_path\n",
    "        df_labels = pd.read_csv(data_path + 'labels.csv', sep=',', header=None)\n",
    "        self.labels = df_labels.values.astype(np.float32)\n",
    "        self.val = val\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # process color frame, using defined augmentations\n",
    "        image = cv2.imread(self.data_path + 'images/' + str(idx) + '.jpg')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # process depth data, convert to tensor\n",
    "        depth = cv2.imread(self.data_path + 'depth/' + str(idx) + '.jpg', 0)\n",
    "        depth = transforms.ToTensor()(depth)\n",
    "        \n",
    "        # concat with color frame\n",
    "        concat = torch.cat((image, depth))\n",
    "        return (concat, self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "# Perform data augmentation only on color frames, but not depth data.\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "data_train = ARCDataset(DATA_PATH + 'train/', transform=train_transforms)\n",
    "print(len(data_train))\n",
    "data_test = ARCDataset(DATA_PATH + 'val/', True, transform=test_transforms)\n",
    "print(len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = model.loss(output, label)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('{} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                time.ctime(time.time()),\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return np.mean(losses)\n",
    "\n",
    "def test(model, device, test_loader, log_interval=None):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, label) in enumerate(test_loader):\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            output = model(data)\n",
    "            test_loss_on = model.loss(output, label, reduction='sum').item()\n",
    "            test_loss += test_loss_on\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: ' + str(test_loss) + '\\n')\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model\n",
    "# RL Epoch 35 loss: 0.009380207437316131 \n",
    "# LL Epoch 42 loss: 0.012472578078159132\n",
    "\n",
    "class CaeLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CaeLeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 64, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, 1, 1)\n",
    "        self.fc1 = nn.Linear(80*60*256, 100)\n",
    "        self.fc2_1 = nn.Linear(100, 1)\n",
    "        self.fc2_2 = nn.Linear(100, 1)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        \n",
    "        self.lowest_error = float(\"inf\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 80*60*256)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        throttle = self.fc2_1(x)\n",
    "        angle = self.fc2_2(x)\n",
    "        return torch.cat((throttle, angle), 1)\n",
    "        \n",
    "    def loss(self, prediction, label, reduction='mean'):\n",
    "        loss = F.mse_loss(prediction, label, reduction = reduction)\n",
    "        return loss\n",
    "    \n",
    "    def save_model(self, file_path, num_to_keep=1):\n",
    "        pt_util.save(self, file_path, num_to_keep)\n",
    "        \n",
    "    def save_best_model(self, error, file_path, num_to_keep=1):\n",
    "        if error < self.lowest_error:\n",
    "          self.lowest_error = error\n",
    "          pt_util.save(self, file_path, num_to_keep)\n",
    "\n",
    "    def load_model(self, file_path):\n",
    "        pt_util.restore(self, file_path)\n",
    "\n",
    "    def load_last_model(self, dir_path):\n",
    "        return pt_util.restore_latest(self, dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "num cpus: 16\n",
      "\n",
      "Test set: Average loss: 0.25452835116535427\n",
      "\n",
      "Mon Dec  2 18:01:36 2019 Train Epoch: 0 [0/3200 (0%)]\tLoss: 0.074653\n",
      "Mon Dec  2 18:01:52 2019 Train Epoch: 0 [1000/3200 (31%)]\tLoss: 0.029783\n",
      "Mon Dec  2 18:02:08 2019 Train Epoch: 0 [2000/3200 (62%)]\tLoss: 0.033214\n",
      "Mon Dec  2 18:02:24 2019 Train Epoch: 0 [3000/3200 (94%)]\tLoss: 0.017588\n",
      "\n",
      "Test set: Average loss: 0.05783337225215291\n",
      "\n",
      "Saved /home/wangc21/datasets/ARC/left_loop/checkpoints/000.pt\n",
      "\n",
      "Mon Dec  2 18:02:33 2019 Train Epoch: 1 [0/3200 (0%)]\tLoss: 0.023997\n",
      "Mon Dec  2 18:02:49 2019 Train Epoch: 1 [1000/3200 (31%)]\tLoss: 0.042144\n",
      "Mon Dec  2 18:03:05 2019 Train Epoch: 1 [2000/3200 (62%)]\tLoss: 0.013860\n",
      "Mon Dec  2 18:03:21 2019 Train Epoch: 1 [3000/3200 (94%)]\tLoss: 0.026921\n",
      "\n",
      "Test set: Average loss: 0.024976413917902392\n",
      "\n",
      "Saved /home/wangc21/datasets/ARC/left_loop/checkpoints/001.pt\n",
      "\n",
      "Mon Dec  2 18:03:30 2019 Train Epoch: 2 [0/3200 (0%)]\tLoss: 0.022521\n",
      "Mon Dec  2 18:03:46 2019 Train Epoch: 2 [1000/3200 (31%)]\tLoss: 0.013483\n",
      "Mon Dec  2 18:04:02 2019 Train Epoch: 2 [2000/3200 (62%)]\tLoss: 0.025369\n",
      "Mon Dec  2 18:04:18 2019 Train Epoch: 2 [3000/3200 (94%)]\tLoss: 0.023406\n",
      "\n",
      "Test set: Average loss: 0.028122466830827763\n",
      "\n",
      "Mon Dec  2 18:04:27 2019 Train Epoch: 3 [0/3200 (0%)]\tLoss: 0.016293\n",
      "Mon Dec  2 18:04:43 2019 Train Epoch: 3 [1000/3200 (31%)]\tLoss: 0.023321\n",
      "Mon Dec  2 18:04:59 2019 Train Epoch: 3 [2000/3200 (62%)]\tLoss: 0.010182\n",
      "Mon Dec  2 18:05:15 2019 Train Epoch: 3 [3000/3200 (94%)]\tLoss: 0.010664\n",
      "\n",
      "Test set: Average loss: 0.01904195419730968\n",
      "\n",
      "Saved /home/wangc21/datasets/ARC/left_loop/checkpoints/003.pt\n",
      "\n",
      "Mon Dec  2 18:05:25 2019 Train Epoch: 4 [0/3200 (0%)]\tLoss: 0.009153\n",
      "Mon Dec  2 18:05:41 2019 Train Epoch: 4 [1000/3200 (31%)]\tLoss: 0.016834\n",
      "Mon Dec  2 18:05:57 2019 Train Epoch: 4 [2000/3200 (62%)]\tLoss: 0.007961\n",
      "Mon Dec  2 18:06:12 2019 Train Epoch: 4 [3000/3200 (94%)]\tLoss: 0.004712\n",
      "\n",
      "Test set: Average loss: 0.0176809943059925\n",
      "\n",
      "Saved /home/wangc21/datasets/ARC/left_loop/checkpoints/004.pt\n",
      "\n",
      "Mon Dec  2 18:06:22 2019 Train Epoch: 5 [0/3200 (0%)]\tLoss: 0.004876\n",
      "Mon Dec  2 18:06:38 2019 Train Epoch: 5 [1000/3200 (31%)]\tLoss: 0.010768\n",
      "Mon Dec  2 18:06:54 2019 Train Epoch: 5 [2000/3200 (62%)]\tLoss: 0.041619\n",
      "Mon Dec  2 18:07:10 2019 Train Epoch: 5 [3000/3200 (94%)]\tLoss: 0.013255\n",
      "\n",
      "Test set: Average loss: 0.01739559879875742\n",
      "\n",
      "Saved /home/wangc21/datasets/ARC/left_loop/checkpoints/005.pt\n",
      "\n",
      "Mon Dec  2 18:07:20 2019 Train Epoch: 6 [0/3200 (0%)]\tLoss: 0.006158\n",
      "Mon Dec  2 18:07:35 2019 Train Epoch: 6 [1000/3200 (31%)]\tLoss: 0.018193\n",
      "Mon Dec  2 18:07:51 2019 Train Epoch: 6 [2000/3200 (62%)]\tLoss: 0.010467\n",
      "Mon Dec  2 18:08:07 2019 Train Epoch: 6 [3000/3200 (94%)]\tLoss: 0.008893\n",
      "\n",
      "Test set: Average loss: 0.01668108985351864\n",
      "\n",
      "Saved /home/wangc21/datasets/ARC/left_loop/checkpoints/006.pt\n",
      "\n",
      "Mon Dec  2 18:08:17 2019 Train Epoch: 7 [0/3200 (0%)]\tLoss: 0.008965\n",
      "Mon Dec  2 18:08:33 2019 Train Epoch: 7 [1000/3200 (31%)]\tLoss: 0.018207\n",
      "Mon Dec  2 18:08:49 2019 Train Epoch: 7 [2000/3200 (62%)]\tLoss: 0.008621\n",
      "Mon Dec  2 18:09:04 2019 Train Epoch: 7 [3000/3200 (94%)]\tLoss: 0.017295\n",
      "\n",
      "Test set: Average loss: 0.020815500513417646\n",
      "\n",
      "Mon Dec  2 18:09:14 2019 Train Epoch: 8 [0/3200 (0%)]\tLoss: 0.004066\n",
      "Mon Dec  2 18:09:30 2019 Train Epoch: 8 [1000/3200 (31%)]\tLoss: 0.007230\n",
      "Mon Dec  2 18:09:46 2019 Train Epoch: 8 [2000/3200 (62%)]\tLoss: 0.006624\n",
      "Mon Dec  2 18:10:01 2019 Train Epoch: 8 [3000/3200 (94%)]\tLoss: 0.010151\n",
      "\n",
      "Test set: Average loss: 0.01979705540201394\n",
      "\n",
      "Mon Dec  2 18:10:11 2019 Train Epoch: 9 [0/3200 (0%)]\tLoss: 0.007976\n",
      "Mon Dec  2 18:10:27 2019 Train Epoch: 9 [1000/3200 (31%)]\tLoss: 0.009749\n",
      "Mon Dec  2 18:10:42 2019 Train Epoch: 9 [2000/3200 (62%)]\tLoss: 0.005147\n",
      "Mon Dec  2 18:10:58 2019 Train Epoch: 9 [3000/3200 (94%)]\tLoss: 0.004306\n",
      "\n",
      "Test set: Average loss: 0.02017237676656805\n",
      "\n",
      "Mon Dec  2 18:11:08 2019 Train Epoch: 10 [0/3200 (0%)]\tLoss: 0.003390\n",
      "Mon Dec  2 18:11:24 2019 Train Epoch: 10 [1000/3200 (31%)]\tLoss: 0.006465\n",
      "Mon Dec  2 18:11:41 2019 Train Epoch: 10 [2000/3200 (62%)]\tLoss: 0.009754\n",
      "Mon Dec  2 18:11:58 2019 Train Epoch: 10 [3000/3200 (94%)]\tLoss: 0.003387\n",
      "\n",
      "Test set: Average loss: 0.0177257277345052\n",
      "\n",
      "Mon Dec  2 18:12:09 2019 Train Epoch: 11 [0/3200 (0%)]\tLoss: 0.005554\n",
      "Mon Dec  2 18:12:25 2019 Train Epoch: 11 [1000/3200 (31%)]\tLoss: 0.012142\n",
      "Mon Dec  2 18:12:40 2019 Train Epoch: 11 [2000/3200 (62%)]\tLoss: 0.007421\n",
      "Mon Dec  2 18:12:56 2019 Train Epoch: 11 [3000/3200 (94%)]\tLoss: 0.004472\n",
      "\n",
      "Test set: Average loss: 0.016885077979532072\n",
      "\n",
      "Mon Dec  2 18:13:05 2019 Train Epoch: 12 [0/3200 (0%)]\tLoss: 0.006223\n",
      "Mon Dec  2 18:13:22 2019 Train Epoch: 12 [1000/3200 (31%)]\tLoss: 0.003309\n",
      "Mon Dec  2 18:13:37 2019 Train Epoch: 12 [2000/3200 (62%)]\tLoss: 0.005003\n",
      "Mon Dec  2 18:13:53 2019 Train Epoch: 12 [3000/3200 (94%)]\tLoss: 0.003193\n",
      "\n",
      "Test set: Average loss: 0.015720519499736837\n",
      "\n",
      "Saved /home/wangc21/datasets/ARC/left_loop/checkpoints/012.pt\n",
      "\n",
      "Mon Dec  2 18:14:03 2019 Train Epoch: 13 [0/3200 (0%)]\tLoss: 0.005642\n",
      "Mon Dec  2 18:14:20 2019 Train Epoch: 13 [1000/3200 (31%)]\tLoss: 0.005927\n",
      "Mon Dec  2 18:14:37 2019 Train Epoch: 13 [2000/3200 (62%)]\tLoss: 0.004438\n",
      "Mon Dec  2 18:14:53 2019 Train Epoch: 13 [3000/3200 (94%)]\tLoss: 0.004508\n",
      "\n",
      "Test set: Average loss: 0.01869440535781905\n",
      "\n",
      "Mon Dec  2 18:15:03 2019 Train Epoch: 14 [0/3200 (0%)]\tLoss: 0.010388\n",
      "Mon Dec  2 18:15:19 2019 Train Epoch: 14 [1000/3200 (31%)]\tLoss: 0.007468\n",
      "Mon Dec  2 18:15:36 2019 Train Epoch: 14 [2000/3200 (62%)]\tLoss: 0.005866\n",
      "Mon Dec  2 18:15:53 2019 Train Epoch: 14 [3000/3200 (94%)]\tLoss: 0.017275\n",
      "\n",
      "Test set: Average loss: 0.01738050812156871\n",
      "\n",
      "Mon Dec  2 18:16:02 2019 Train Epoch: 15 [0/3200 (0%)]\tLoss: 0.003399\n",
      "Mon Dec  2 18:16:19 2019 Train Epoch: 15 [1000/3200 (31%)]\tLoss: 0.005496\n",
      "Mon Dec  2 18:16:36 2019 Train Epoch: 15 [2000/3200 (62%)]\tLoss: 0.024923\n",
      "Mon Dec  2 18:16:52 2019 Train Epoch: 15 [3000/3200 (94%)]\tLoss: 0.005742\n",
      "\n",
      "Test set: Average loss: 0.019053128104133066\n",
      "\n",
      "Mon Dec  2 18:17:02 2019 Train Epoch: 16 [0/3200 (0%)]\tLoss: 0.015016\n",
      "Mon Dec  2 18:17:18 2019 Train Epoch: 16 [1000/3200 (31%)]\tLoss: 0.004736\n",
      "Mon Dec  2 18:17:34 2019 Train Epoch: 16 [2000/3200 (62%)]\tLoss: 0.007645\n",
      "Mon Dec  2 18:17:50 2019 Train Epoch: 16 [3000/3200 (94%)]\tLoss: 0.003766\n",
      "\n",
      "Test set: Average loss: 0.017838282131997403\n",
      "\n",
      "Mon Dec  2 18:17:59 2019 Train Epoch: 17 [0/3200 (0%)]\tLoss: 0.006317\n",
      "Mon Dec  2 18:18:17 2019 Train Epoch: 17 [1000/3200 (31%)]\tLoss: 0.005871\n",
      "Mon Dec  2 18:18:34 2019 Train Epoch: 17 [2000/3200 (62%)]\tLoss: 0.004239\n",
      "Mon Dec  2 18:18:50 2019 Train Epoch: 17 [3000/3200 (94%)]\tLoss: 0.004718\n",
      "\n",
      "Test set: Average loss: 0.014298298146459274\n",
      "\n",
      "Saved /home/wangc21/datasets/ARC/left_loop/checkpoints/017.pt\n",
      "\n",
      "Mon Dec  2 18:19:00 2019 Train Epoch: 18 [0/3200 (0%)]\tLoss: 0.005595\n",
      "Mon Dec  2 18:19:16 2019 Train Epoch: 18 [1000/3200 (31%)]\tLoss: 0.004663\n",
      "Mon Dec  2 18:19:32 2019 Train Epoch: 18 [2000/3200 (62%)]\tLoss: 0.003813\n",
      "Mon Dec  2 18:19:48 2019 Train Epoch: 18 [3000/3200 (94%)]\tLoss: 0.002977\n",
      "\n",
      "Test set: Average loss: 0.019412277771625668\n",
      "\n",
      "Mon Dec  2 18:19:57 2019 Train Epoch: 19 [0/3200 (0%)]\tLoss: 0.002566\n",
      "Mon Dec  2 18:20:15 2019 Train Epoch: 19 [1000/3200 (31%)]\tLoss: 0.007943\n",
      "Mon Dec  2 18:20:30 2019 Train Epoch: 19 [2000/3200 (62%)]\tLoss: 0.007749\n",
      "Mon Dec  2 18:20:46 2019 Train Epoch: 19 [3000/3200 (94%)]\tLoss: 0.010517\n",
      "\n",
      "Test set: Average loss: 0.017310752193588998\n",
      "\n",
      "Mon Dec  2 18:20:56 2019 Train Epoch: 20 [0/3200 (0%)]\tLoss: 0.012917\n",
      "Mon Dec  2 18:21:13 2019 Train Epoch: 20 [1000/3200 (31%)]\tLoss: 0.004245\n",
      "Mon Dec  2 18:21:29 2019 Train Epoch: 20 [2000/3200 (62%)]\tLoss: 0.002730\n",
      "Mon Dec  2 18:21:45 2019 Train Epoch: 20 [3000/3200 (94%)]\tLoss: 0.003352\n",
      "\n",
      "Test set: Average loss: 0.016596403629519044\n",
      "\n",
      "Mon Dec  2 18:21:55 2019 Train Epoch: 21 [0/3200 (0%)]\tLoss: 0.001920\n",
      "Mon Dec  2 18:22:11 2019 Train Epoch: 21 [1000/3200 (31%)]\tLoss: 0.003438\n",
      "Mon Dec  2 18:22:27 2019 Train Epoch: 21 [2000/3200 (62%)]\tLoss: 0.005437\n",
      "Mon Dec  2 18:22:43 2019 Train Epoch: 21 [3000/3200 (94%)]\tLoss: 0.003087\n",
      "\n",
      "Test set: Average loss: 0.016683417517342605\n",
      "\n",
      "Mon Dec  2 18:22:52 2019 Train Epoch: 22 [0/3200 (0%)]\tLoss: 0.014790\n",
      "Mon Dec  2 18:23:08 2019 Train Epoch: 22 [1000/3200 (31%)]\tLoss: 0.005311\n",
      "Mon Dec  2 18:23:24 2019 Train Epoch: 22 [2000/3200 (62%)]\tLoss: 0.003051\n",
      "Mon Dec  2 18:23:39 2019 Train Epoch: 22 [3000/3200 (94%)]\tLoss: 0.009938\n",
      "\n",
      "Test set: Average loss: 0.015621782754315063\n",
      "\n",
      "Mon Dec  2 18:23:49 2019 Train Epoch: 23 [0/3200 (0%)]\tLoss: 0.003840\n",
      "Mon Dec  2 18:24:05 2019 Train Epoch: 23 [1000/3200 (31%)]\tLoss: 0.021469\n",
      "Mon Dec  2 18:24:21 2019 Train Epoch: 23 [2000/3200 (62%)]\tLoss: 0.031450\n",
      "Mon Dec  2 18:24:37 2019 Train Epoch: 23 [3000/3200 (94%)]\tLoss: 0.012982\n",
      "\n",
      "Test set: Average loss: 0.03481778866553213\n",
      "\n",
      "Mon Dec  2 18:24:46 2019 Train Epoch: 24 [0/3200 (0%)]\tLoss: 0.023943\n",
      "Mon Dec  2 18:25:02 2019 Train Epoch: 24 [1000/3200 (31%)]\tLoss: 0.007820\n",
      "Mon Dec  2 18:25:18 2019 Train Epoch: 24 [2000/3200 (62%)]\tLoss: 0.005516\n",
      "Mon Dec  2 18:25:34 2019 Train Epoch: 24 [3000/3200 (94%)]\tLoss: 0.007479\n",
      "\n",
      "Test set: Average loss: 0.026168905082158744\n",
      "\n",
      "Mon Dec  2 18:25:43 2019 Train Epoch: 25 [0/3200 (0%)]\tLoss: 0.003226\n",
      "Mon Dec  2 18:25:59 2019 Train Epoch: 25 [1000/3200 (31%)]\tLoss: 0.023417\n",
      "Mon Dec  2 18:26:16 2019 Train Epoch: 25 [2000/3200 (62%)]\tLoss: 0.014486\n",
      "Mon Dec  2 18:26:32 2019 Train Epoch: 25 [3000/3200 (94%)]\tLoss: 0.005057\n",
      "\n",
      "Test set: Average loss: 0.019059135871357283\n",
      "\n",
      "Mon Dec  2 18:26:43 2019 Train Epoch: 26 [0/3200 (0%)]\tLoss: 0.007632\n",
      "Mon Dec  2 18:26:59 2019 Train Epoch: 26 [1000/3200 (31%)]\tLoss: 0.010504\n",
      "Mon Dec  2 18:27:14 2019 Train Epoch: 26 [2000/3200 (62%)]\tLoss: 0.010866\n",
      "Mon Dec  2 18:27:30 2019 Train Epoch: 26 [3000/3200 (94%)]\tLoss: 0.009011\n",
      "\n",
      "Test set: Average loss: 0.016603225073049545\n",
      "\n",
      "Mon Dec  2 18:27:40 2019 Train Epoch: 27 [0/3200 (0%)]\tLoss: 0.001927\n",
      "Mon Dec  2 18:27:57 2019 Train Epoch: 27 [1000/3200 (31%)]\tLoss: 0.011673\n",
      "Mon Dec  2 18:28:13 2019 Train Epoch: 27 [2000/3200 (62%)]\tLoss: 0.002344\n",
      "Mon Dec  2 18:28:29 2019 Train Epoch: 27 [3000/3200 (94%)]\tLoss: 0.003557\n",
      "\n",
      "Test set: Average loss: 0.016644395379116758\n",
      "\n",
      "Mon Dec  2 18:28:39 2019 Train Epoch: 28 [0/3200 (0%)]\tLoss: 0.006449\n",
      "Mon Dec  2 18:28:54 2019 Train Epoch: 28 [1000/3200 (31%)]\tLoss: 0.005555\n",
      "Mon Dec  2 18:29:10 2019 Train Epoch: 28 [2000/3200 (62%)]\tLoss: 0.013670\n",
      "Mon Dec  2 18:29:26 2019 Train Epoch: 28 [3000/3200 (94%)]\tLoss: 0.016927\n",
      "\n",
      "Test set: Average loss: 0.01907823602843564\n",
      "\n",
      "Mon Dec  2 18:29:36 2019 Train Epoch: 29 [0/3200 (0%)]\tLoss: 0.004801\n",
      "Mon Dec  2 18:29:52 2019 Train Epoch: 29 [1000/3200 (31%)]\tLoss: 0.003881\n",
      "Mon Dec  2 18:30:08 2019 Train Epoch: 29 [2000/3200 (62%)]\tLoss: 0.002860\n",
      "Mon Dec  2 18:30:24 2019 Train Epoch: 29 [3000/3200 (94%)]\tLoss: 0.009552\n",
      "\n",
      "Test set: Average loss: 0.018926922124519477\n",
      "\n",
      "Mon Dec  2 18:30:33 2019 Train Epoch: 30 [0/3200 (0%)]\tLoss: 0.005824\n",
      "Mon Dec  2 18:30:50 2019 Train Epoch: 30 [1000/3200 (31%)]\tLoss: 0.004425\n",
      "Mon Dec  2 18:31:06 2019 Train Epoch: 30 [2000/3200 (62%)]\tLoss: 0.006845\n",
      "Mon Dec  2 18:31:22 2019 Train Epoch: 30 [3000/3200 (94%)]\tLoss: 0.005637\n",
      "\n",
      "Test set: Average loss: 0.015891917810949962\n",
      "\n",
      "Mon Dec  2 18:31:32 2019 Train Epoch: 31 [0/3200 (0%)]\tLoss: 0.012376\n",
      "Mon Dec  2 18:31:48 2019 Train Epoch: 31 [1000/3200 (31%)]\tLoss: 0.004485\n",
      "Mon Dec  2 18:32:03 2019 Train Epoch: 31 [2000/3200 (62%)]\tLoss: 0.006986\n",
      "Mon Dec  2 18:32:19 2019 Train Epoch: 31 [3000/3200 (94%)]\tLoss: 0.006436\n",
      "\n",
      "Test set: Average loss: 0.014828552255348768\n",
      "\n",
      "Mon Dec  2 18:32:29 2019 Train Epoch: 32 [0/3200 (0%)]\tLoss: 0.007986\n",
      "Mon Dec  2 18:32:45 2019 Train Epoch: 32 [1000/3200 (31%)]\tLoss: 0.006114\n",
      "Mon Dec  2 18:33:02 2019 Train Epoch: 32 [2000/3200 (62%)]\tLoss: 0.007714\n",
      "Mon Dec  2 18:33:17 2019 Train Epoch: 32 [3000/3200 (94%)]\tLoss: 0.003097\n",
      "\n",
      "Test set: Average loss: 0.017178002194850706\n",
      "\n",
      "Mon Dec  2 18:33:28 2019 Train Epoch: 33 [0/3200 (0%)]\tLoss: 0.006081\n",
      "Mon Dec  2 18:33:43 2019 Train Epoch: 33 [1000/3200 (31%)]\tLoss: 0.004799\n",
      "Mon Dec  2 18:33:59 2019 Train Epoch: 33 [2000/3200 (62%)]\tLoss: 0.003155\n",
      "Mon Dec  2 18:34:15 2019 Train Epoch: 33 [3000/3200 (94%)]\tLoss: 0.011886\n",
      "\n",
      "Test set: Average loss: 0.015861624473473057\n",
      "\n",
      "Mon Dec  2 18:34:25 2019 Train Epoch: 34 [0/3200 (0%)]\tLoss: 0.005408\n",
      "Mon Dec  2 18:34:41 2019 Train Epoch: 34 [1000/3200 (31%)]\tLoss: 0.002886\n",
      "Mon Dec  2 18:34:57 2019 Train Epoch: 34 [2000/3200 (62%)]\tLoss: 0.004697\n",
      "Mon Dec  2 18:35:12 2019 Train Epoch: 34 [3000/3200 (94%)]\tLoss: 0.003700\n",
      "\n",
      "Test set: Average loss: 0.014637125618755818\n",
      "\n",
      "Mon Dec  2 18:35:22 2019 Train Epoch: 35 [0/3200 (0%)]\tLoss: 0.007162\n",
      "Mon Dec  2 18:35:38 2019 Train Epoch: 35 [1000/3200 (31%)]\tLoss: 0.006037\n",
      "Mon Dec  2 18:35:54 2019 Train Epoch: 35 [2000/3200 (62%)]\tLoss: 0.003979\n",
      "Mon Dec  2 18:36:10 2019 Train Epoch: 35 [3000/3200 (94%)]\tLoss: 0.003439\n",
      "\n",
      "Test set: Average loss: 0.01661788614350371\n",
      "\n",
      "Mon Dec  2 18:36:20 2019 Train Epoch: 36 [0/3200 (0%)]\tLoss: 0.002100\n",
      "Mon Dec  2 18:36:36 2019 Train Epoch: 36 [1000/3200 (31%)]\tLoss: 0.002079\n",
      "Mon Dec  2 18:36:52 2019 Train Epoch: 36 [2000/3200 (62%)]\tLoss: 0.015191\n",
      "Mon Dec  2 18:37:08 2019 Train Epoch: 36 [3000/3200 (94%)]\tLoss: 0.007999\n",
      "\n",
      "Test set: Average loss: 0.016372646343370434\n",
      "\n",
      "Mon Dec  2 18:37:18 2019 Train Epoch: 37 [0/3200 (0%)]\tLoss: 0.002215\n",
      "Mon Dec  2 18:37:34 2019 Train Epoch: 37 [1000/3200 (31%)]\tLoss: 0.001797\n",
      "Mon Dec  2 18:37:50 2019 Train Epoch: 37 [2000/3200 (62%)]\tLoss: 0.006853\n",
      "Mon Dec  2 18:38:06 2019 Train Epoch: 37 [3000/3200 (94%)]\tLoss: 0.009982\n",
      "\n",
      "Test set: Average loss: 0.016654280014918185\n",
      "\n",
      "Mon Dec  2 18:38:15 2019 Train Epoch: 38 [0/3200 (0%)]\tLoss: 0.002918\n",
      "Mon Dec  2 18:38:31 2019 Train Epoch: 38 [1000/3200 (31%)]\tLoss: 0.002758\n",
      "Mon Dec  2 18:38:47 2019 Train Epoch: 38 [2000/3200 (62%)]\tLoss: 0.004376\n",
      "Mon Dec  2 18:39:03 2019 Train Epoch: 38 [3000/3200 (94%)]\tLoss: 0.003758\n",
      "\n",
      "Test set: Average loss: 0.018010169896297158\n",
      "\n",
      "Mon Dec  2 18:39:13 2019 Train Epoch: 39 [0/3200 (0%)]\tLoss: 0.007763\n",
      "Mon Dec  2 18:39:29 2019 Train Epoch: 39 [1000/3200 (31%)]\tLoss: 0.003576\n",
      "Mon Dec  2 18:39:45 2019 Train Epoch: 39 [2000/3200 (62%)]\tLoss: 0.014562\n",
      "Mon Dec  2 18:40:01 2019 Train Epoch: 39 [3000/3200 (94%)]\tLoss: 0.006421\n",
      "\n",
      "Test set: Average loss: 0.0146894901903579\n",
      "\n",
      "Mon Dec  2 18:40:10 2019 Train Epoch: 40 [0/3200 (0%)]\tLoss: 0.005703\n",
      "Mon Dec  2 18:40:26 2019 Train Epoch: 40 [1000/3200 (31%)]\tLoss: 0.005125\n",
      "Mon Dec  2 18:40:42 2019 Train Epoch: 40 [2000/3200 (62%)]\tLoss: 0.002281\n",
      "Mon Dec  2 18:40:58 2019 Train Epoch: 40 [3000/3200 (94%)]\tLoss: 0.012533\n",
      "\n",
      "Test set: Average loss: 0.016320743305841462\n",
      "\n",
      "Mon Dec  2 18:41:08 2019 Train Epoch: 41 [0/3200 (0%)]\tLoss: 0.003313\n",
      "Mon Dec  2 18:41:24 2019 Train Epoch: 41 [1000/3200 (31%)]\tLoss: 0.004275\n",
      "Mon Dec  2 18:41:40 2019 Train Epoch: 41 [2000/3200 (62%)]\tLoss: 0.004311\n",
      "Mon Dec  2 18:41:56 2019 Train Epoch: 41 [3000/3200 (94%)]\tLoss: 0.004654\n",
      "\n",
      "Test set: Average loss: 0.015577110953163355\n",
      "\n",
      "Mon Dec  2 18:42:05 2019 Train Epoch: 42 [0/3200 (0%)]\tLoss: 0.001803\n",
      "Mon Dec  2 18:42:22 2019 Train Epoch: 42 [1000/3200 (31%)]\tLoss: 0.003503\n",
      "Mon Dec  2 18:42:37 2019 Train Epoch: 42 [2000/3200 (62%)]\tLoss: 0.003740\n",
      "Mon Dec  2 18:42:53 2019 Train Epoch: 42 [3000/3200 (94%)]\tLoss: 0.009293\n",
      "\n",
      "Test set: Average loss: 0.012472578078159132\n",
      "\n",
      "Saved /home/wangc21/datasets/ARC/left_loop/checkpoints/042.pt\n",
      "\n",
      "Mon Dec  2 18:43:04 2019 Train Epoch: 43 [0/3200 (0%)]\tLoss: 0.002584\n",
      "Mon Dec  2 18:43:20 2019 Train Epoch: 43 [1000/3200 (31%)]\tLoss: 0.007511\n",
      "Mon Dec  2 18:43:36 2019 Train Epoch: 43 [2000/3200 (62%)]\tLoss: 0.007529\n",
      "Mon Dec  2 18:43:52 2019 Train Epoch: 43 [3000/3200 (94%)]\tLoss: 0.006225\n",
      "\n",
      "Test set: Average loss: 0.0151007789207506\n",
      "\n",
      "Mon Dec  2 18:44:02 2019 Train Epoch: 44 [0/3200 (0%)]\tLoss: 0.007853\n",
      "Mon Dec  2 18:44:18 2019 Train Epoch: 44 [1000/3200 (31%)]\tLoss: 0.003494\n",
      "Mon Dec  2 18:44:34 2019 Train Epoch: 44 [2000/3200 (62%)]\tLoss: 0.009181\n",
      "Mon Dec  2 18:44:50 2019 Train Epoch: 44 [3000/3200 (94%)]\tLoss: 0.010497\n",
      "\n",
      "Test set: Average loss: 0.01674965990066994\n",
      "\n",
      "Mon Dec  2 18:45:00 2019 Train Epoch: 45 [0/3200 (0%)]\tLoss: 0.004857\n",
      "Mon Dec  2 18:45:16 2019 Train Epoch: 45 [1000/3200 (31%)]\tLoss: 0.005022\n",
      "Mon Dec  2 18:45:32 2019 Train Epoch: 45 [2000/3200 (62%)]\tLoss: 0.007096\n",
      "Mon Dec  2 18:45:48 2019 Train Epoch: 45 [3000/3200 (94%)]\tLoss: 0.003836\n",
      "\n",
      "Test set: Average loss: 0.017192390661657554\n",
      "\n",
      "Mon Dec  2 18:45:58 2019 Train Epoch: 46 [0/3200 (0%)]\tLoss: 0.003200\n",
      "Mon Dec  2 18:46:14 2019 Train Epoch: 46 [1000/3200 (31%)]\tLoss: 0.005203\n",
      "Mon Dec  2 18:46:30 2019 Train Epoch: 46 [2000/3200 (62%)]\tLoss: 0.004403\n",
      "Mon Dec  2 18:46:46 2019 Train Epoch: 46 [3000/3200 (94%)]\tLoss: 0.005209\n",
      "\n",
      "Test set: Average loss: 0.017131094336509705\n",
      "\n",
      "Mon Dec  2 18:46:56 2019 Train Epoch: 47 [0/3200 (0%)]\tLoss: 0.003953\n",
      "Mon Dec  2 18:47:12 2019 Train Epoch: 47 [1000/3200 (31%)]\tLoss: 0.002510\n",
      "Mon Dec  2 18:47:28 2019 Train Epoch: 47 [2000/3200 (62%)]\tLoss: 0.005676\n",
      "Mon Dec  2 18:47:44 2019 Train Epoch: 47 [3000/3200 (94%)]\tLoss: 0.004698\n",
      "\n",
      "Test set: Average loss: 0.014336045871605165\n",
      "\n",
      "Mon Dec  2 18:47:53 2019 Train Epoch: 48 [0/3200 (0%)]\tLoss: 0.005074\n",
      "Mon Dec  2 18:48:09 2019 Train Epoch: 48 [1000/3200 (31%)]\tLoss: 0.001071\n",
      "Mon Dec  2 18:48:25 2019 Train Epoch: 48 [2000/3200 (62%)]\tLoss: 0.003077\n",
      "Mon Dec  2 18:48:41 2019 Train Epoch: 48 [3000/3200 (94%)]\tLoss: 0.002234\n",
      "\n",
      "Test set: Average loss: 0.016372586810030045\n",
      "\n",
      "Mon Dec  2 18:48:50 2019 Train Epoch: 49 [0/3200 (0%)]\tLoss: 0.002002\n",
      "Mon Dec  2 18:49:06 2019 Train Epoch: 49 [1000/3200 (31%)]\tLoss: 0.002374\n",
      "Mon Dec  2 18:49:22 2019 Train Epoch: 49 [2000/3200 (62%)]\tLoss: 0.004339\n",
      "Mon Dec  2 18:49:38 2019 Train Epoch: 49 [3000/3200 (94%)]\tLoss: 0.006051\n",
      "\n",
      "Test set: Average loss: 0.014319540715951007\n",
      "\n",
      "Mon Dec  2 18:49:47 2019 Train Epoch: 50 [0/3200 (0%)]\tLoss: 0.008315\n",
      "Mon Dec  2 18:50:03 2019 Train Epoch: 50 [1000/3200 (31%)]\tLoss: 0.003315\n",
      "Mon Dec  2 18:50:19 2019 Train Epoch: 50 [2000/3200 (62%)]\tLoss: 0.004876\n",
      "Mon Dec  2 18:50:34 2019 Train Epoch: 50 [3000/3200 (94%)]\tLoss: 0.002387\n",
      "\n",
      "Test set: Average loss: 0.016507619770709425\n",
      "\n",
      "Mon Dec  2 18:50:44 2019 Train Epoch: 51 [0/3200 (0%)]\tLoss: 0.001969\n",
      "Mon Dec  2 18:51:00 2019 Train Epoch: 51 [1000/3200 (31%)]\tLoss: 0.008390\n",
      "Mon Dec  2 18:51:16 2019 Train Epoch: 51 [2000/3200 (62%)]\tLoss: 0.004136\n",
      "Mon Dec  2 18:51:32 2019 Train Epoch: 51 [3000/3200 (94%)]\tLoss: 0.006726\n",
      "\n",
      "Test set: Average loss: 0.01694570742372889\n",
      "\n",
      "Mon Dec  2 18:51:42 2019 Train Epoch: 52 [0/3200 (0%)]\tLoss: 0.003347\n",
      "Mon Dec  2 18:51:57 2019 Train Epoch: 52 [1000/3200 (31%)]\tLoss: 0.004142\n",
      "Mon Dec  2 18:52:13 2019 Train Epoch: 52 [2000/3200 (62%)]\tLoss: 0.006767\n",
      "Mon Dec  2 18:52:29 2019 Train Epoch: 52 [3000/3200 (94%)]\tLoss: 0.003415\n",
      "\n",
      "Test set: Average loss: 0.016891936626925598\n",
      "\n",
      "Mon Dec  2 18:52:39 2019 Train Epoch: 53 [0/3200 (0%)]\tLoss: 0.003229\n",
      "Mon Dec  2 18:52:54 2019 Train Epoch: 53 [1000/3200 (31%)]\tLoss: 0.004553\n",
      "Mon Dec  2 18:53:10 2019 Train Epoch: 53 [2000/3200 (62%)]\tLoss: 0.004651\n",
      "Mon Dec  2 18:53:26 2019 Train Epoch: 53 [3000/3200 (94%)]\tLoss: 0.006112\n",
      "\n",
      "Test set: Average loss: 0.01648891589982668\n",
      "\n",
      "Mon Dec  2 18:53:35 2019 Train Epoch: 54 [0/3200 (0%)]\tLoss: 0.001994\n",
      "Mon Dec  2 18:53:51 2019 Train Epoch: 54 [1000/3200 (31%)]\tLoss: 0.004224\n",
      "Mon Dec  2 18:54:07 2019 Train Epoch: 54 [2000/3200 (62%)]\tLoss: 0.003818\n",
      "Mon Dec  2 18:54:23 2019 Train Epoch: 54 [3000/3200 (94%)]\tLoss: 0.003345\n",
      "\n",
      "Test set: Average loss: 0.014985946383676492\n",
      "\n",
      "Mon Dec  2 18:54:33 2019 Train Epoch: 55 [0/3200 (0%)]\tLoss: 0.003793\n",
      "Mon Dec  2 18:54:48 2019 Train Epoch: 55 [1000/3200 (31%)]\tLoss: 0.003730\n",
      "Mon Dec  2 18:55:04 2019 Train Epoch: 55 [2000/3200 (62%)]\tLoss: 0.008042\n",
      "Mon Dec  2 18:55:20 2019 Train Epoch: 55 [3000/3200 (94%)]\tLoss: 0.007951\n",
      "\n",
      "Test set: Average loss: 0.0151587519783061\n",
      "\n",
      "Mon Dec  2 18:55:29 2019 Train Epoch: 56 [0/3200 (0%)]\tLoss: 0.006075\n",
      "Mon Dec  2 18:55:45 2019 Train Epoch: 56 [1000/3200 (31%)]\tLoss: 0.004130\n",
      "Mon Dec  2 18:56:01 2019 Train Epoch: 56 [2000/3200 (62%)]\tLoss: 0.004733\n",
      "Mon Dec  2 18:56:17 2019 Train Epoch: 56 [3000/3200 (94%)]\tLoss: 0.004748\n",
      "\n",
      "Test set: Average loss: 0.014707271334482358\n",
      "\n",
      "Mon Dec  2 18:56:26 2019 Train Epoch: 57 [0/3200 (0%)]\tLoss: 0.006565\n",
      "Mon Dec  2 18:56:42 2019 Train Epoch: 57 [1000/3200 (31%)]\tLoss: 0.006773\n",
      "Mon Dec  2 18:56:58 2019 Train Epoch: 57 [2000/3200 (62%)]\tLoss: 0.006166\n",
      "Mon Dec  2 18:57:14 2019 Train Epoch: 57 [3000/3200 (94%)]\tLoss: 0.002564\n",
      "\n",
      "Test set: Average loss: 0.013208396235131658\n",
      "\n",
      "Mon Dec  2 18:57:23 2019 Train Epoch: 58 [0/3200 (0%)]\tLoss: 0.004593\n",
      "Mon Dec  2 18:57:39 2019 Train Epoch: 58 [1000/3200 (31%)]\tLoss: 0.005980\n",
      "Mon Dec  2 18:57:55 2019 Train Epoch: 58 [2000/3200 (62%)]\tLoss: 0.004867\n",
      "Mon Dec  2 18:58:11 2019 Train Epoch: 58 [3000/3200 (94%)]\tLoss: 0.002401\n",
      "\n",
      "Test set: Average loss: 0.01615584078099346\n",
      "\n",
      "Mon Dec  2 18:58:20 2019 Train Epoch: 59 [0/3200 (0%)]\tLoss: 0.003880\n",
      "Mon Dec  2 18:58:36 2019 Train Epoch: 59 [1000/3200 (31%)]\tLoss: 0.004441\n",
      "Mon Dec  2 18:58:52 2019 Train Epoch: 59 [2000/3200 (62%)]\tLoss: 0.003388\n",
      "Mon Dec  2 18:59:07 2019 Train Epoch: 59 [3000/3200 (94%)]\tLoss: 0.003283\n",
      "\n",
      "Test set: Average loss: 0.013499377889093011\n",
      "\n",
      "Mon Dec  2 18:59:18 2019 Train Epoch: 60 [0/3200 (0%)]\tLoss: 0.004581\n",
      "Mon Dec  2 18:59:33 2019 Train Epoch: 60 [1000/3200 (31%)]\tLoss: 0.006335\n",
      "Mon Dec  2 18:59:49 2019 Train Epoch: 60 [2000/3200 (62%)]\tLoss: 0.002526\n",
      "Mon Dec  2 19:00:05 2019 Train Epoch: 60 [3000/3200 (94%)]\tLoss: 0.002162\n",
      "\n",
      "Test set: Average loss: 0.012873656764277257\n",
      "\n",
      "Mon Dec  2 19:00:15 2019 Train Epoch: 61 [0/3200 (0%)]\tLoss: 0.006966\n",
      "Mon Dec  2 19:00:30 2019 Train Epoch: 61 [1000/3200 (31%)]\tLoss: 0.003770\n",
      "Mon Dec  2 19:00:46 2019 Train Epoch: 61 [2000/3200 (62%)]\tLoss: 0.003880\n",
      "Mon Dec  2 19:01:02 2019 Train Epoch: 61 [3000/3200 (94%)]\tLoss: 0.007150\n",
      "\n",
      "Test set: Average loss: 0.015268317526206374\n",
      "\n",
      "Mon Dec  2 19:01:11 2019 Train Epoch: 62 [0/3200 (0%)]\tLoss: 0.004084\n",
      "Mon Dec  2 19:01:27 2019 Train Epoch: 62 [1000/3200 (31%)]\tLoss: 0.003162\n",
      "Mon Dec  2 19:01:43 2019 Train Epoch: 62 [2000/3200 (62%)]\tLoss: 0.004516\n",
      "Mon Dec  2 19:01:59 2019 Train Epoch: 62 [3000/3200 (94%)]\tLoss: 0.012934\n",
      "\n",
      "Test set: Average loss: 0.015547330668196082\n",
      "\n",
      "Mon Dec  2 19:02:09 2019 Train Epoch: 63 [0/3200 (0%)]\tLoss: 0.004906\n",
      "Mon Dec  2 19:02:25 2019 Train Epoch: 63 [1000/3200 (31%)]\tLoss: 0.005474\n",
      "Mon Dec  2 19:02:40 2019 Train Epoch: 63 [2000/3200 (62%)]\tLoss: 0.003192\n",
      "Mon Dec  2 19:02:56 2019 Train Epoch: 63 [3000/3200 (94%)]\tLoss: 0.010101\n",
      "\n",
      "Test set: Average loss: 0.020613872078829445\n",
      "\n",
      "Mon Dec  2 19:03:06 2019 Train Epoch: 64 [0/3200 (0%)]\tLoss: 0.002708\n",
      "Mon Dec  2 19:03:22 2019 Train Epoch: 64 [1000/3200 (31%)]\tLoss: 0.002394\n",
      "Mon Dec  2 19:03:37 2019 Train Epoch: 64 [2000/3200 (62%)]\tLoss: 0.007890\n",
      "Mon Dec  2 19:03:53 2019 Train Epoch: 64 [3000/3200 (94%)]\tLoss: 0.002288\n",
      "\n",
      "Test set: Average loss: 0.01477273652330041\n",
      "\n",
      "Mon Dec  2 19:04:03 2019 Train Epoch: 65 [0/3200 (0%)]\tLoss: 0.002776\n",
      "Mon Dec  2 19:04:19 2019 Train Epoch: 65 [1000/3200 (31%)]\tLoss: 0.007970\n",
      "Mon Dec  2 19:04:35 2019 Train Epoch: 65 [2000/3200 (62%)]\tLoss: 0.003949\n",
      "Mon Dec  2 19:04:50 2019 Train Epoch: 65 [3000/3200 (94%)]\tLoss: 0.003141\n",
      "\n",
      "Test set: Average loss: 0.01420045341248624\n",
      "\n",
      "Mon Dec  2 19:05:00 2019 Train Epoch: 66 [0/3200 (0%)]\tLoss: 0.002189\n",
      "Mon Dec  2 19:05:16 2019 Train Epoch: 66 [1000/3200 (31%)]\tLoss: 0.002650\n",
      "Mon Dec  2 19:05:32 2019 Train Epoch: 66 [2000/3200 (62%)]\tLoss: 0.002918\n",
      "Mon Dec  2 19:05:48 2019 Train Epoch: 66 [3000/3200 (94%)]\tLoss: 0.003790\n",
      "\n",
      "Test set: Average loss: 0.014929980367887764\n",
      "\n",
      "Mon Dec  2 19:05:57 2019 Train Epoch: 67 [0/3200 (0%)]\tLoss: 0.003184\n",
      "Mon Dec  2 19:06:13 2019 Train Epoch: 67 [1000/3200 (31%)]\tLoss: 0.001400\n",
      "Mon Dec  2 19:06:29 2019 Train Epoch: 67 [2000/3200 (62%)]\tLoss: 0.006091\n",
      "Mon Dec  2 19:06:44 2019 Train Epoch: 67 [3000/3200 (94%)]\tLoss: 0.004030\n",
      "\n",
      "Test set: Average loss: 0.01710811258177273\n",
      "\n",
      "Mon Dec  2 19:06:54 2019 Train Epoch: 68 [0/3200 (0%)]\tLoss: 0.004469\n",
      "Mon Dec  2 19:07:10 2019 Train Epoch: 68 [1000/3200 (31%)]\tLoss: 0.003116\n",
      "Mon Dec  2 19:07:26 2019 Train Epoch: 68 [2000/3200 (62%)]\tLoss: 0.004406\n",
      "Mon Dec  2 19:07:41 2019 Train Epoch: 68 [3000/3200 (94%)]\tLoss: 0.006089\n",
      "\n",
      "Test set: Average loss: 0.017019967029627877\n",
      "\n",
      "Mon Dec  2 19:07:51 2019 Train Epoch: 69 [0/3200 (0%)]\tLoss: 0.005755\n",
      "Mon Dec  2 19:08:07 2019 Train Epoch: 69 [1000/3200 (31%)]\tLoss: 0.003635\n",
      "Mon Dec  2 19:08:23 2019 Train Epoch: 69 [2000/3200 (62%)]\tLoss: 0.002887\n",
      "Mon Dec  2 19:08:38 2019 Train Epoch: 69 [3000/3200 (94%)]\tLoss: 0.006859\n",
      "\n",
      "Test set: Average loss: 0.014675608576508238\n",
      "\n",
      "Mon Dec  2 19:08:48 2019 Train Epoch: 70 [0/3200 (0%)]\tLoss: 0.005228\n",
      "Mon Dec  2 19:09:04 2019 Train Epoch: 70 [1000/3200 (31%)]\tLoss: 0.003494\n",
      "Mon Dec  2 19:09:20 2019 Train Epoch: 70 [2000/3200 (62%)]\tLoss: 0.002795\n",
      "Mon Dec  2 19:09:35 2019 Train Epoch: 70 [3000/3200 (94%)]\tLoss: 0.003957\n",
      "\n",
      "Test set: Average loss: 0.014219454505946487\n",
      "\n",
      "Mon Dec  2 19:09:45 2019 Train Epoch: 71 [0/3200 (0%)]\tLoss: 0.003560\n",
      "Mon Dec  2 19:10:01 2019 Train Epoch: 71 [1000/3200 (31%)]\tLoss: 0.002227\n",
      "Mon Dec  2 19:10:17 2019 Train Epoch: 71 [2000/3200 (62%)]\tLoss: 0.003011\n",
      "Mon Dec  2 19:10:32 2019 Train Epoch: 71 [3000/3200 (94%)]\tLoss: 0.009386\n",
      "\n",
      "Test set: Average loss: 0.013805339619284495\n",
      "\n",
      "Mon Dec  2 19:10:42 2019 Train Epoch: 72 [0/3200 (0%)]\tLoss: 0.002442\n",
      "Mon Dec  2 19:10:58 2019 Train Epoch: 72 [1000/3200 (31%)]\tLoss: 0.005611\n",
      "Mon Dec  2 19:11:13 2019 Train Epoch: 72 [2000/3200 (62%)]\tLoss: 0.005725\n",
      "Mon Dec  2 19:11:29 2019 Train Epoch: 72 [3000/3200 (94%)]\tLoss: 0.002496\n",
      "\n",
      "Test set: Average loss: 0.015023584161535836\n",
      "\n",
      "Mon Dec  2 19:11:38 2019 Train Epoch: 73 [0/3200 (0%)]\tLoss: 0.002074\n",
      "Mon Dec  2 19:11:54 2019 Train Epoch: 73 [1000/3200 (31%)]\tLoss: 0.001944\n",
      "Mon Dec  2 19:12:10 2019 Train Epoch: 73 [2000/3200 (62%)]\tLoss: 0.003918\n",
      "Mon Dec  2 19:12:26 2019 Train Epoch: 73 [3000/3200 (94%)]\tLoss: 0.005275\n",
      "\n",
      "Test set: Average loss: 0.014637478265794925\n",
      "\n",
      "Mon Dec  2 19:12:35 2019 Train Epoch: 74 [0/3200 (0%)]\tLoss: 0.004056\n",
      "Mon Dec  2 19:12:51 2019 Train Epoch: 74 [1000/3200 (31%)]\tLoss: 0.003741\n",
      "Mon Dec  2 19:13:06 2019 Train Epoch: 74 [2000/3200 (62%)]\tLoss: 0.002605\n",
      "Mon Dec  2 19:13:22 2019 Train Epoch: 74 [3000/3200 (94%)]\tLoss: 0.002833\n",
      "\n",
      "Test set: Average loss: 0.02241184263024479\n",
      "\n",
      "Mon Dec  2 19:13:32 2019 Train Epoch: 75 [0/3200 (0%)]\tLoss: 0.004949\n",
      "Mon Dec  2 19:13:48 2019 Train Epoch: 75 [1000/3200 (31%)]\tLoss: 0.004863\n",
      "Mon Dec  2 19:14:03 2019 Train Epoch: 75 [2000/3200 (62%)]\tLoss: 0.006219\n",
      "Mon Dec  2 19:14:19 2019 Train Epoch: 75 [3000/3200 (94%)]\tLoss: 0.005844\n",
      "\n",
      "Test set: Average loss: 0.01495031369064236\n",
      "\n",
      "Mon Dec  2 19:14:29 2019 Train Epoch: 76 [0/3200 (0%)]\tLoss: 0.003531\n",
      "Mon Dec  2 19:14:45 2019 Train Epoch: 76 [1000/3200 (31%)]\tLoss: 0.003856\n",
      "Mon Dec  2 19:15:00 2019 Train Epoch: 76 [2000/3200 (62%)]\tLoss: 0.003263\n",
      "Mon Dec  2 19:15:16 2019 Train Epoch: 76 [3000/3200 (94%)]\tLoss: 0.006400\n",
      "\n",
      "Test set: Average loss: 0.014751596445858012\n",
      "\n",
      "Mon Dec  2 19:15:25 2019 Train Epoch: 77 [0/3200 (0%)]\tLoss: 0.005987\n",
      "Mon Dec  2 19:15:41 2019 Train Epoch: 77 [1000/3200 (31%)]\tLoss: 0.003135\n",
      "Mon Dec  2 19:15:57 2019 Train Epoch: 77 [2000/3200 (62%)]\tLoss: 0.003319\n",
      "Mon Dec  2 19:16:12 2019 Train Epoch: 77 [3000/3200 (94%)]\tLoss: 0.005603\n",
      "\n",
      "Test set: Average loss: 0.015239899510052056\n",
      "\n",
      "Mon Dec  2 19:16:22 2019 Train Epoch: 78 [0/3200 (0%)]\tLoss: 0.002730\n",
      "Mon Dec  2 19:16:38 2019 Train Epoch: 78 [1000/3200 (31%)]\tLoss: 0.003378\n",
      "Mon Dec  2 19:16:54 2019 Train Epoch: 78 [2000/3200 (62%)]\tLoss: 0.008686\n",
      "Mon Dec  2 19:17:09 2019 Train Epoch: 78 [3000/3200 (94%)]\tLoss: 0.002061\n",
      "\n",
      "Test set: Average loss: 0.016512120457482526\n",
      "\n",
      "Mon Dec  2 19:17:19 2019 Train Epoch: 79 [0/3200 (0%)]\tLoss: 0.007223\n",
      "Mon Dec  2 19:17:35 2019 Train Epoch: 79 [1000/3200 (31%)]\tLoss: 0.005108\n",
      "Mon Dec  2 19:17:50 2019 Train Epoch: 79 [2000/3200 (62%)]\tLoss: 0.003066\n",
      "Mon Dec  2 19:18:06 2019 Train Epoch: 79 [3000/3200 (94%)]\tLoss: 0.002570\n",
      "\n",
      "Test set: Average loss: 0.017067210760433226\n",
      "\n",
      "Mon Dec  2 19:18:16 2019 Train Epoch: 80 [0/3200 (0%)]\tLoss: 0.005446\n",
      "Mon Dec  2 19:18:31 2019 Train Epoch: 80 [1000/3200 (31%)]\tLoss: 0.005730\n",
      "Mon Dec  2 19:18:47 2019 Train Epoch: 80 [2000/3200 (62%)]\tLoss: 0.002505\n",
      "Mon Dec  2 19:19:02 2019 Train Epoch: 80 [3000/3200 (94%)]\tLoss: 0.004859\n",
      "\n",
      "Test set: Average loss: 0.015637693317257798\n",
      "\n",
      "Mon Dec  2 19:19:12 2019 Train Epoch: 81 [0/3200 (0%)]\tLoss: 0.001520\n",
      "Mon Dec  2 19:19:28 2019 Train Epoch: 81 [1000/3200 (31%)]\tLoss: 0.004590\n",
      "Mon Dec  2 19:19:44 2019 Train Epoch: 81 [2000/3200 (62%)]\tLoss: 0.007301\n",
      "Mon Dec  2 19:19:59 2019 Train Epoch: 81 [3000/3200 (94%)]\tLoss: 0.007454\n",
      "\n",
      "Test set: Average loss: 0.01571102187881479\n",
      "\n",
      "Mon Dec  2 19:20:09 2019 Train Epoch: 82 [0/3200 (0%)]\tLoss: 0.002604\n",
      "Mon Dec  2 19:20:25 2019 Train Epoch: 82 [1000/3200 (31%)]\tLoss: 0.004647\n",
      "Mon Dec  2 19:20:41 2019 Train Epoch: 82 [2000/3200 (62%)]\tLoss: 0.002680\n",
      "Mon Dec  2 19:20:56 2019 Train Epoch: 82 [3000/3200 (94%)]\tLoss: 0.001493\n",
      "\n",
      "Test set: Average loss: 0.016453289350611158\n",
      "\n",
      "Mon Dec  2 19:21:06 2019 Train Epoch: 83 [0/3200 (0%)]\tLoss: 0.002679\n",
      "Mon Dec  2 19:21:22 2019 Train Epoch: 83 [1000/3200 (31%)]\tLoss: 0.004582\n",
      "Mon Dec  2 19:21:38 2019 Train Epoch: 83 [2000/3200 (62%)]\tLoss: 0.002780\n",
      "Mon Dec  2 19:21:53 2019 Train Epoch: 83 [3000/3200 (94%)]\tLoss: 0.004923\n",
      "\n",
      "Test set: Average loss: 0.016030610088491812\n",
      "\n",
      "Mon Dec  2 19:22:03 2019 Train Epoch: 84 [0/3200 (0%)]\tLoss: 0.004986\n",
      "Mon Dec  2 19:22:19 2019 Train Epoch: 84 [1000/3200 (31%)]\tLoss: 0.002707\n",
      "Mon Dec  2 19:22:34 2019 Train Epoch: 84 [2000/3200 (62%)]\tLoss: 0.006612\n",
      "Mon Dec  2 19:22:50 2019 Train Epoch: 84 [3000/3200 (94%)]\tLoss: 0.002373\n",
      "\n",
      "Test set: Average loss: 0.01703443914098898\n",
      "\n",
      "Mon Dec  2 19:23:00 2019 Train Epoch: 85 [0/3200 (0%)]\tLoss: 0.001796\n",
      "Mon Dec  2 19:23:15 2019 Train Epoch: 85 [1000/3200 (31%)]\tLoss: 0.005427\n",
      "Mon Dec  2 19:23:31 2019 Train Epoch: 85 [2000/3200 (62%)]\tLoss: 0.003003\n",
      "Mon Dec  2 19:23:46 2019 Train Epoch: 85 [3000/3200 (94%)]\tLoss: 0.002841\n",
      "\n",
      "Test set: Average loss: 0.014613195439451374\n",
      "\n",
      "Mon Dec  2 19:23:56 2019 Train Epoch: 86 [0/3200 (0%)]\tLoss: 0.005538\n",
      "Mon Dec  2 19:24:12 2019 Train Epoch: 86 [1000/3200 (31%)]\tLoss: 0.005642\n",
      "Mon Dec  2 19:24:28 2019 Train Epoch: 86 [2000/3200 (62%)]\tLoss: 0.004686\n",
      "Mon Dec  2 19:24:43 2019 Train Epoch: 86 [3000/3200 (94%)]\tLoss: 0.003745\n",
      "\n",
      "Test set: Average loss: 0.015605733531992882\n",
      "\n",
      "Mon Dec  2 19:24:53 2019 Train Epoch: 87 [0/3200 (0%)]\tLoss: 0.003628\n",
      "Mon Dec  2 19:25:09 2019 Train Epoch: 87 [1000/3200 (31%)]\tLoss: 0.004964\n",
      "Mon Dec  2 19:25:24 2019 Train Epoch: 87 [2000/3200 (62%)]\tLoss: 0.002485\n",
      "Mon Dec  2 19:25:40 2019 Train Epoch: 87 [3000/3200 (94%)]\tLoss: 0.008445\n",
      "\n",
      "Test set: Average loss: 0.016424330924637617\n",
      "\n",
      "Mon Dec  2 19:25:49 2019 Train Epoch: 88 [0/3200 (0%)]\tLoss: 0.003007\n",
      "Mon Dec  2 19:26:05 2019 Train Epoch: 88 [1000/3200 (31%)]\tLoss: 0.003572\n",
      "Mon Dec  2 19:26:21 2019 Train Epoch: 88 [2000/3200 (62%)]\tLoss: 0.002245\n",
      "Mon Dec  2 19:26:36 2019 Train Epoch: 88 [3000/3200 (94%)]\tLoss: 0.003696\n",
      "\n",
      "Test set: Average loss: 0.014906956190243363\n",
      "\n",
      "Mon Dec  2 19:26:46 2019 Train Epoch: 89 [0/3200 (0%)]\tLoss: 0.006730\n",
      "Mon Dec  2 19:27:01 2019 Train Epoch: 89 [1000/3200 (31%)]\tLoss: 0.004629\n",
      "Mon Dec  2 19:27:17 2019 Train Epoch: 89 [2000/3200 (62%)]\tLoss: 0.008435\n",
      "Mon Dec  2 19:27:33 2019 Train Epoch: 89 [3000/3200 (94%)]\tLoss: 0.004963\n",
      "\n",
      "Test set: Average loss: 0.013651782369561261\n",
      "\n",
      "Mon Dec  2 19:27:42 2019 Train Epoch: 90 [0/3200 (0%)]\tLoss: 0.004371\n",
      "Mon Dec  2 19:27:58 2019 Train Epoch: 90 [1000/3200 (31%)]\tLoss: 0.003241\n",
      "Mon Dec  2 19:28:14 2019 Train Epoch: 90 [2000/3200 (62%)]\tLoss: 0.000886\n",
      "Mon Dec  2 19:28:29 2019 Train Epoch: 90 [3000/3200 (94%)]\tLoss: 0.003211\n",
      "\n",
      "Test set: Average loss: 0.014910125187889207\n",
      "\n",
      "Mon Dec  2 19:28:39 2019 Train Epoch: 91 [0/3200 (0%)]\tLoss: 0.003424\n",
      "Mon Dec  2 19:28:55 2019 Train Epoch: 91 [1000/3200 (31%)]\tLoss: 0.008797\n",
      "Mon Dec  2 19:29:10 2019 Train Epoch: 91 [2000/3200 (62%)]\tLoss: 0.018634\n",
      "Mon Dec  2 19:29:26 2019 Train Epoch: 91 [3000/3200 (94%)]\tLoss: 0.006189\n",
      "\n",
      "Test set: Average loss: 0.016910588548344093\n",
      "\n",
      "Mon Dec  2 19:29:35 2019 Train Epoch: 92 [0/3200 (0%)]\tLoss: 0.003121\n",
      "Mon Dec  2 19:29:51 2019 Train Epoch: 92 [1000/3200 (31%)]\tLoss: 0.004164\n",
      "Mon Dec  2 19:30:06 2019 Train Epoch: 92 [2000/3200 (62%)]\tLoss: 0.004752\n",
      "Mon Dec  2 19:30:22 2019 Train Epoch: 92 [3000/3200 (94%)]\tLoss: 0.003496\n",
      "\n",
      "Test set: Average loss: 0.01673453889117809\n",
      "\n",
      "Mon Dec  2 19:30:31 2019 Train Epoch: 93 [0/3200 (0%)]\tLoss: 0.003620\n",
      "Mon Dec  2 19:30:47 2019 Train Epoch: 93 [1000/3200 (31%)]\tLoss: 0.005859\n",
      "Mon Dec  2 19:31:03 2019 Train Epoch: 93 [2000/3200 (62%)]\tLoss: 0.006599\n",
      "Mon Dec  2 19:31:18 2019 Train Epoch: 93 [3000/3200 (94%)]\tLoss: 0.012146\n",
      "\n",
      "Test set: Average loss: 0.01692159512662329\n",
      "\n",
      "Mon Dec  2 19:31:28 2019 Train Epoch: 94 [0/3200 (0%)]\tLoss: 0.003320\n",
      "Mon Dec  2 19:31:44 2019 Train Epoch: 94 [1000/3200 (31%)]\tLoss: 0.003796\n",
      "Mon Dec  2 19:31:59 2019 Train Epoch: 94 [2000/3200 (62%)]\tLoss: 0.002309\n",
      "Mon Dec  2 19:32:15 2019 Train Epoch: 94 [3000/3200 (94%)]\tLoss: 0.003970\n",
      "\n",
      "Test set: Average loss: 0.015547140829730778\n",
      "\n",
      "Mon Dec  2 19:32:25 2019 Train Epoch: 95 [0/3200 (0%)]\tLoss: 0.005927\n",
      "Mon Dec  2 19:32:41 2019 Train Epoch: 95 [1000/3200 (31%)]\tLoss: 0.002189\n",
      "Mon Dec  2 19:32:56 2019 Train Epoch: 95 [2000/3200 (62%)]\tLoss: 0.006377\n",
      "Mon Dec  2 19:33:12 2019 Train Epoch: 95 [3000/3200 (94%)]\tLoss: 0.004702\n",
      "\n",
      "Test set: Average loss: 0.014621212514466606\n",
      "\n",
      "Mon Dec  2 19:33:22 2019 Train Epoch: 96 [0/3200 (0%)]\tLoss: 0.002434\n",
      "Mon Dec  2 19:33:37 2019 Train Epoch: 96 [1000/3200 (31%)]\tLoss: 0.003242\n",
      "Mon Dec  2 19:33:53 2019 Train Epoch: 96 [2000/3200 (62%)]\tLoss: 0.001757\n",
      "Mon Dec  2 19:34:08 2019 Train Epoch: 96 [3000/3200 (94%)]\tLoss: 0.002741\n",
      "\n",
      "Test set: Average loss: 0.016372265494428575\n",
      "\n",
      "Mon Dec  2 19:34:18 2019 Train Epoch: 97 [0/3200 (0%)]\tLoss: 0.002124\n",
      "Mon Dec  2 19:34:33 2019 Train Epoch: 97 [1000/3200 (31%)]\tLoss: 0.005679\n",
      "Mon Dec  2 19:34:49 2019 Train Epoch: 97 [2000/3200 (62%)]\tLoss: 0.002126\n",
      "Mon Dec  2 19:35:05 2019 Train Epoch: 97 [3000/3200 (94%)]\tLoss: 0.004785\n",
      "\n",
      "Test set: Average loss: 0.017830255750741344\n",
      "\n",
      "Mon Dec  2 19:35:14 2019 Train Epoch: 98 [0/3200 (0%)]\tLoss: 0.004868\n",
      "Mon Dec  2 19:35:30 2019 Train Epoch: 98 [1000/3200 (31%)]\tLoss: 0.007502\n",
      "Mon Dec  2 19:35:45 2019 Train Epoch: 98 [2000/3200 (62%)]\tLoss: 0.002315\n",
      "Mon Dec  2 19:36:01 2019 Train Epoch: 98 [3000/3200 (94%)]\tLoss: 0.007621\n",
      "\n",
      "Test set: Average loss: 0.019157537419814616\n",
      "\n",
      "Mon Dec  2 19:36:10 2019 Train Epoch: 99 [0/3200 (0%)]\tLoss: 0.002917\n",
      "Mon Dec  2 19:36:26 2019 Train Epoch: 99 [1000/3200 (31%)]\tLoss: 0.002030\n",
      "Mon Dec  2 19:36:42 2019 Train Epoch: 99 [2000/3200 (62%)]\tLoss: 0.002894\n",
      "Mon Dec  2 19:36:57 2019 Train Epoch: 99 [3000/3200 (94%)]\tLoss: 0.006741\n",
      "\n",
      "Test set: Average loss: 0.016396334934979676\n",
      "\n",
      "Mon Dec  2 19:37:07 2019 Train Epoch: 100 [0/3200 (0%)]\tLoss: 0.004380\n",
      "Mon Dec  2 19:37:23 2019 Train Epoch: 100 [1000/3200 (31%)]\tLoss: 0.001926\n",
      "Mon Dec  2 19:37:38 2019 Train Epoch: 100 [2000/3200 (62%)]\tLoss: 0.003141\n",
      "Mon Dec  2 19:37:54 2019 Train Epoch: 100 [3000/3200 (94%)]\tLoss: 0.005175\n",
      "\n",
      "Test set: Average loss: 0.019400437848526055\n",
      "\n",
      "Saved /home/wangc21/datasets/ARC/left_loop/checkpoints/100.pt\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Play around with these constants, you may find a better setting.\n",
    "BATCH_SIZE = 10\n",
    "TEST_BATCH_SIZE = 5\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.9\n",
    "USE_CUDA = True\n",
    "SEED = 0\n",
    "PRINT_INTERVAL = 100\n",
    "WEIGHT_DECAY = 0.0005\n",
    "LOG_PATH = DATA_PATH + 'log.pkl'\n",
    "# Now the actual training code\n",
    "use_cuda = USE_CUDA and torch.cuda.is_available()\n",
    "\n",
    "#torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print('Using device', device)\n",
    "import multiprocessing\n",
    "print('num cpus:', multiprocessing.cpu_count())\n",
    "\n",
    "kwargs = {'num_workers': multiprocessing.cpu_count(),\n",
    "          'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=BATCH_SIZE,\n",
    "                                           shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=TEST_BATCH_SIZE,\n",
    "                                          shuffle=False, **kwargs)\n",
    "\n",
    "model = CaeLeNet().to(device)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "#start_epoch = model.load_last_model(DATA_PATH + 'checkpoints')\n",
    "start_epoch = 0\n",
    "\n",
    "train_losses, test_losses = pt_util.read_log(LOG_PATH, ([], []))\n",
    "test_loss = test(model, device, test_loader)\n",
    "test_losses.append((start_epoch, test_loss))\n",
    "\n",
    "try:\n",
    "    for epoch in range(start_epoch, EPOCHS + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch, PRINT_INTERVAL)\n",
    "        test_loss = test(model, device, test_loader)\n",
    "        train_losses.append((epoch, train_loss))\n",
    "        test_losses.append((epoch, test_loss))\n",
    "        pt_util.write_log(LOG_PATH, (train_losses, test_losses))\n",
    "        model.save_best_model(test_loss, DATA_PATH + 'checkpoints/%03d.pt' % epoch)\n",
    "\n",
    "\n",
    "except KeyboardInterrupt as ke:\n",
    "    print('Interrupted')\n",
    "except:\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    model.save_model(DATA_PATH + 'checkpoints/%03d.pt' % epoch, 0)\n",
    "    ep, val = zip(*train_losses)\n",
    "    pt_util.plot(ep, val, 'Train loss', 'Epoch', 'Error')\n",
    "    ep, val = zip(*test_losses)\n",
    "    pt_util.plot(ep, val, 'Test loss', 'Epoch', 'Error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
